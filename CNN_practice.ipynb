{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ちゃんとCNNをかけるように練習したやつ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = fetch_mldata('MNIST original')\n",
    "X = mnist['data']\n",
    "y = mnist['target']\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]\n",
    "index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[index], y_train[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_batch(X, y, batch_size):\n",
    "    rnd_idx = np.random.permutation(len(X))\n",
    "    n_batches = len(X) // batch_size\n",
    "    for batch_idx in np.array_split(rnd_idx, n_batches):\n",
    "        X_batch, y_batch = X[batch_idx], y[batch_idx]\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "def minibatch(X, y, batch_size):\n",
    "    index = np.random.randint(0, len(X), batch_size)\n",
    "    #print(index)\n",
    "    X_batch, y_batch = X[index], y[index]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_outputs = 10\n",
    "height, width = 28, 28\n",
    "channel = 1\n",
    "\n",
    "n_conv1_map = 32\n",
    "conv1_filter_size = 2\n",
    "conv1_stride = 1\n",
    "\n",
    "n_conv2_map = 64\n",
    "conv2_filter_size = 2\n",
    "conv2_stride = 1\n",
    "\n",
    "n_conv3_map = 80\n",
    "conv3_filter_size = 2\n",
    "conv3_stride = 2\n",
    "#learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "reshaped_X = tf.reshape(X, shape=(-1, height, width, channel))\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('CNN'):\n",
    "    conv1 = tf.layers.conv2d(reshaped_X, filters=n_conv1_map, kernel_size=conv1_filter_size, \n",
    "                             strides=conv1_stride, padding='SAME', activation=tf.nn.relu, name=\"conv1\")\n",
    "    conv2 = tf.layers.conv2d(conv1, filters=n_conv2_map, kernel_size=conv2_filter_size,\n",
    "                             strides=conv2_stride, padding='SAME', activation=tf.nn.relu, name='conv2')\n",
    "    conv3 = tf.layers.conv2d(conv2, filters=n_conv3_map, kernel_size=conv3_filter_size, \n",
    "                             strides=conv3_stride, padding='SAME', activation=tf.nn.relu, name='conv3')\n",
    "    reshape_conv3 = tf.reshape(conv3,shape=(-1, 14*14*n_conv3_map))\n",
    "    fc = tf.layers.dense(reshape_conv3, n_conv3_map, name='fully_connect')\n",
    "    tf.shape(fc)\n",
    "    output = tf.layers.dense(fc, n_outputs, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(output, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 15\n",
    "batch_size= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.957\n",
      "accuracy:  0.963\n",
      "accuracy:  0.97\n",
      "accuracy:  0.972\n",
      "accuracy:  0.973\n",
      "accuracy:  0.971\n",
      "accuracy:  0.979\n",
      "accuracy:  0.973\n",
      "accuracy:  0.984\n",
      "accuracy:  0.971\n",
      "accuracy:  0.984\n",
      "accuracy:  0.973\n",
      "accuracy:  0.981\n",
      "accuracy:  0.981\n",
      "accuracy:  0.983\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        X_test_batch, y_test_batch = minibatch(X_test, y_test, batch_size=1000)\n",
    "        acc = accuracy.eval(feed_dict={X: X_test_batch,y: y_test_batch})\n",
    "        print(\"accuracy: \", acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_outputs = 10\n",
    "height, width = 28, 28\n",
    "channel = 1\n",
    "\n",
    "n_conv1_map = 32\n",
    "conv1_filter_size = 2\n",
    "conv1_stride = 1\n",
    "\n",
    "n_conv2_map = 64\n",
    "conv2_filter_size = 2\n",
    "conv2_stride = 1\n",
    "\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "reshaped_X = tf.reshape(X, shape=(-1, height, width, channel))\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('CNN'):\n",
    "    conv1 = tf.layers.conv2d(reshaped_X, filters=n_conv1_map, kernel_size=conv1_filter_size, \n",
    "                             strides=conv1_stride, padding='SAME', activation=tf.nn.relu, name=\"conv1\")\n",
    "    conv2 = tf.layers.conv2d(conv1, filters=n_conv2_map, kernel_size=conv2_filter_size,\n",
    "                             strides=conv2_stride, padding='SAME', activation=tf.nn.relu, name='conv2')\n",
    "    reshape_conv2 = tf.reshape(conv2,shape=(-1, 28*28*64))\n",
    "    fc = tf.layers.dense(reshape_conv2, 64, name='fully_connect')\n",
    "    tf.shape(fc)\n",
    "    output = tf.layers.dense(fc, n_outputs, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(output, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 15\n",
    "batch_size= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.971\n",
      "accuracy:  0.978\n",
      "accuracy:  0.969\n",
      "accuracy:  0.977\n",
      "accuracy:  0.965\n",
      "accuracy:  0.962\n",
      "accuracy:  0.965\n",
      "accuracy:  0.968\n",
      "accuracy:  0.958\n",
      "accuracy:  0.974\n",
      "accuracy:  0.975\n",
      "accuracy:  0.967\n",
      "accuracy:  0.979\n",
      "accuracy:  0.964\n",
      "accuracy:  0.967\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        X_test_batch, y_test_batch = minibatch(X_test, y_test, batch_size=1000)\n",
    "        acc = accuracy.eval(feed_dict={X: X_test_batch,y: y_test_batch})\n",
    "        print(\"accuracy: \", acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 conv layers and 1 pool layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 28 * 28\n",
    "n_outputs = 10\n",
    "height, width = 28, 28\n",
    "channel = 1\n",
    "\n",
    "n_conv1_map = 32\n",
    "conv1_filter_size = 2\n",
    "conv1_stride = 1\n",
    "\n",
    "n_conv2_map = 64\n",
    "conv2_filter_size = 2\n",
    "conv2_stride = 1\n",
    "\n",
    "learning_rate = 0.005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=(None, n_inputs), name='X')\n",
    "reshaped_X = tf.reshape(X, shape=(-1, height, width, channel))\n",
    "y = tf.placeholder(tf.int32, shape=(None), name='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('CNN'):\n",
    "    conv1 = tf.layers.conv2d(reshaped_X, filters=n_conv1_map, kernel_size=conv1_filter_size, \n",
    "                             strides=conv1_stride, padding='SAME', activation=tf.nn.relu, name=\"conv1\")\n",
    "    conv2 = tf.layers.conv2d(conv1, filters=n_conv2_map, kernel_size=conv2_filter_size,\n",
    "                             strides=conv2_stride, padding='SAME', activation=tf.nn.relu, name='conv2')\n",
    "    pool1 = tf.nn.max_pool(conv2, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME')\n",
    "    reshape_pool1 = tf.reshape(pool1,shape=(-1, 14*14*64))\n",
    "    fc = tf.layers.dense(reshape_pool1, 64, name='fully_connect')\n",
    "    tf.shape(fc)\n",
    "    output = tf.layers.dense(fc, n_outputs, name='output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=output, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('eval'):\n",
    "    correct = tf.nn.in_top_k(output, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 15\n",
    "batch_size= 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.978\n",
      "accuracy:  0.971\n",
      "accuracy:  0.973\n",
      "accuracy:  0.963\n",
      "accuracy:  0.965\n",
      "accuracy:  0.971\n",
      "accuracy:  0.974\n",
      "accuracy:  0.98\n",
      "accuracy:  0.983\n",
      "accuracy:  0.971\n",
      "accuracy:  0.979\n",
      "accuracy:  0.983\n",
      "accuracy:  0.982\n",
      "accuracy:  0.972\n",
      "accuracy:  0.983\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for X_batch, y_batch in shuffle_batch(X_train, y_train, batch_size):\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch})\n",
    "        X_test_batch, y_test_batch = minibatch(X_test, y_test, batch_size=1000)\n",
    "        acc = accuracy.eval(feed_dict={X: X_test_batch,y: y_test_batch})\n",
    "        print(\"accuracy: \", acc)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
