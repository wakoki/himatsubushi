{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Four Arithmetic Deep Neural Network  \n",
    "Challenge training four arithmetic operation with deep neural network.  \n",
    "This NN compute within three-digits number without zero.  \n",
    "NN architecture image below.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"four_arithmetic_image.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_train = np.random.randint(1, 100, size=(1000000, 2))\n",
    "X_test = np.random.randint(1, 100, size=(10000, 2))\n",
    "y_train_add = np.sum(X_train, axis=1)\n",
    "y_test_add = np.sum(X_test, axis=1)\n",
    "y_train_sub = np.subtract(X_train[:, 0], X_train[:, 1])\n",
    "y_test_sub = np.subtract(X_test[:, 0], X_test[:, 1])\n",
    "y_train_mul = np.multiply(X_train[:, 0], X_train[:, 1])\n",
    "y_test_mul = np.multiply(X_test[:, 0], X_test[:, 1])\n",
    "y_train_div = np.divide(X_train[:, 0], X_train[:, 1])\n",
    "y_test_div = np.divide(X_test[:, 0], X_test[:, 1])\n",
    "train_data = np.c_[X_train, y_train_add, y_train_sub, y_train_mul, y_train_div]\n",
    "test_data = np.c_[X_test, y_test_add, y_test_sub, y_test_mul, y_test_div]\n",
    "y_train, y_test = train_data[:, 2:], test_data[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constract NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_inputs = 2\n",
    "n_hidden1 = 16\n",
    "n_hidden_add = 32\n",
    "n_hidden_sub = 32\n",
    "n_hidden_mul = 32\n",
    "n_hidden_div = 46\n",
    "n_hidden2 = 64\n",
    "n_outputs = 4\n",
    "dropout_rate = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(X, y, batch_size):\n",
    "    n, _ = X.shape\n",
    "    batch_index = np.random.randint(0, n, size=batch_size)\n",
    "    X_batch, y_batch = X[batch_index], y[batch_index]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32, shape=(None, 2), name='X')\n",
    "y = tf.placeholder(tf.float32, shape=(None, 4), name='y')\n",
    "training = tf.placeholder_with_default(False, shape=(), name='training')\n",
    "with tf.name_scope('dnn'):\n",
    "    hidden1 = tf.layers.dense(X, n_hidden1, activation=tf.nn.leaky_relu, name='hidden1')\n",
    "    add = tf.layers.dense(hidden1, n_hidden_add, activation=tf.nn.leaky_relu, name='add')    \n",
    "    sub = tf.layers.dense(hidden1, n_hidden_sub, activation=tf.nn.leaky_relu, name='sub')\n",
    "    mul = tf.layers.dense(hidden1, n_hidden_mul, activation=tf.nn.leaky_relu, name='mul')\n",
    "    div = tf.layers.dense(hidden1, n_hidden_div, activation=tf.nn.leaky_relu, name='div')\n",
    "    four_concat = tf.concat([add, sub, mul, div], 1)\n",
    "    hidden2 = tf.layers.dense(four_concat, n_hidden2, activation=tf.nn.leaky_relu, name='hidden2')\n",
    "    #drop_hidden2 = tf.layers.dropout(hidden2, dropout_rate, training=training)\n",
    "    output = tf.layers.dense(hidden2, n_outputs, name='output')\n",
    "\n",
    "with tf.name_scope('loss'):\n",
    "    loss = tf.reduce_mean(tf.square(output - y), name='loss')\n",
    "    \n",
    "with tf.name_scope('train'):\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope('eval'):\n",
    "    mse = tf.reduce_mean(tf.square(output - y), name='mse')\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse_summary = tf.summary.scalar('MSE', mse)\n",
    "logdir = 'tf_logs/four_arithmetic'\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MSE:  21.287643\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 2000\n",
    "batch_size = 20000\n",
    "n_batchies = int(X_train.shape[0] // batch_size)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    for epoch in range(n_epochs):\n",
    "        for batch_cnt in range(n_batchies):\n",
    "            X_batch, y_batch = fetch_data(X_train, y_train, batch_size=batch_size)\n",
    "            sess.run(training_op, feed_dict={X: X_batch, y: y_batch, training: True})\n",
    "        if epoch % 50 == 0:\n",
    "            MSE = mse_summary.eval(feed_dict={X: X_train, y: y_train})\n",
    "            step = epoch * n_batchies + batch_cnt\n",
    "            file_writer.add_summary(MSE, step)\n",
    "    test_MSE = mse.eval(feed_dict={X: X_test, y: y_test})\n",
    "    print('test MSE: ', test_MSE)\n",
    "    saver.save(sess, 'my_models/four_arithmetic_dnn')\n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test trained NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from my_models/four_arithmetic_dnn\n",
      "[[ 7.8000e+01  1.3000e+01  9.1125e+01  6.4938e+01  1.0055e+03  4.9609e+00]\n",
      " [ 2.0000e+00  1.0000e+00  6.4336e+00  1.9336e+00 -3.3477e+00  2.3359e+00]\n",
      " [ 5.1000e+01  5.6000e+01  1.0706e+02 -4.7773e+00  2.8700e+03  8.0322e-01]\n",
      " ...\n",
      " [ 8.0000e+01  8.6000e+01  1.6600e+02 -5.6484e+00  6.8840e+03  1.2744e-01]\n",
      " [ 2.2000e+01  6.1000e+01  8.2938e+01 -3.9219e+01  1.3400e+03 -4.6045e-01]\n",
      " [ 3.7000e+01  9.9000e+01  1.3575e+02 -6.2656e+01  3.6660e+03 -3.2251e-01]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, 'my_models/four_arithmetic_dnn')\n",
    "    y_pred = output.eval(session=sess, feed_dict={X: X_test})\n",
    "    pred_set = np.float16(np.c_[X_test, y_pred])\n",
    "    print(pred_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.10000000e+01  6.50000000e+01  1.01400000e+03  6.00000000e+00]\n",
      " [ 3.00000000e+00  1.00000000e+00  2.00000000e+00  2.00000000e+00]\n",
      " [ 1.07000000e+02 -5.00000000e+00  2.85600000e+03  9.10714286e-01]\n",
      " ...\n",
      " [ 1.66000000e+02 -6.00000000e+00  6.88000000e+03  9.30232558e-01]\n",
      " [ 8.30000000e+01 -3.90000000e+01  1.34200000e+03  3.60655738e-01]\n",
      " [ 1.36000000e+02 -6.20000000e+01  3.66300000e+03  3.73737374e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary  \n",
    "Divide is difficult ;(  \n",
    "Maybe other computings are good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "a = tf.constant([[1,2,3], [4,5,6]], dtype=tf.int16)\n",
    "b = tf.constant([[7,8,9], [10,11,12]], dtype=tf.int16)\n",
    "c = tf.constant([[13,14,15], [16,17,18]], dtype=tf.int16)\n",
    "d = tf.constant([[19,20,21], [22,23,24]], dtype=tf.int16)\n",
    "concat = tf.concat([a,b,c,d], 1)\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    con_con = concat.eval()\n",
    "    print(con_con)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
